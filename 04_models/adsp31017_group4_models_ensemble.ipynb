{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicare Fraud - Stacking Models\n",
    "\n",
    "Mustapha Mbengue, Peyton Nash, Bradley Stoller, Kyler Rosen\n",
    "\n",
    "3/9/25\n",
    "\n",
    "Purpose: Specifies, trains and evaluates stacking models to classify cases of medicare fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to pre-process this data\n",
    "from adsp31017_group4_data_preprocessing import process_data\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "Merging raw data...\n",
      "Merged raw data. Time elapsed: 10.00s\n",
      "Correcting codes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply data processing script\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m process_data()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check DataFrame head\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Documents/university_of_chicago/02_wint_25/adsp_31017/project/MedicareFraudDetect/adsp31017_group4_data_preprocessing.py:32\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Adjust the diagnosis and claim codes\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrecting codes...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m correct_codes()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrected codes. Time elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Read the dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/university_of_chicago/02_wint_25/adsp_31017/project/MedicareFraudDetect/adsp31017_group4_data_preprocessing.py:263\u001b[0m, in \u001b[0;36mcorrect_codes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# dealing with various NaN formats across records\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m diagnosis_columns \u001b[38;5;241m+\u001b[39m procedure_columns:\n\u001b[0;32m--> 263\u001b[0m     train_data[col] \u001b[38;5;241m=\u001b[39m train_data[col]\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[1;32m    264\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mNA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0nan\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mNA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mNA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAN\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mNA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<NA>\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mNA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mNA},\n\u001b[1;32m    265\u001b[0m         regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     )\n\u001b[1;32m    268\u001b[0m     train_data[col] \u001b[38;5;241m=\u001b[39m train_data[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(fix_icd_format)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# apply the function to fix the format of codes\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:8051\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   8048\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   8049\u001b[0m         to_replace, value \u001b[38;5;241m=\u001b[39m keys, values\n\u001b[0;32m-> 8051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[1;32m   8052\u001b[0m         to_replace, value, inplace\u001b[38;5;241m=\u001b[39minplace, limit\u001b[38;5;241m=\u001b[39mlimit, regex\u001b[38;5;241m=\u001b[39mregex\n\u001b[1;32m   8053\u001b[0m     )\n\u001b[1;32m   8054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   8055\u001b[0m     \u001b[38;5;66;03m# need a non-zero len on all axes\u001b[39;00m\n\u001b[1;32m   8056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:8099\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   8094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_replace) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[1;32m   8095\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   8096\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplacement lists must match in length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8097\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_replace)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   8098\u001b[0m         )\n\u001b[0;32m-> 8099\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreplace_list(\n\u001b[1;32m   8100\u001b[0m         src_list\u001b[38;5;241m=\u001b[39mto_replace,\n\u001b[1;32m   8101\u001b[0m         dest_list\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[1;32m   8102\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   8103\u001b[0m         regex\u001b[38;5;241m=\u001b[39mregex,\n\u001b[1;32m   8104\u001b[0m     )\n\u001b[1;32m   8106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_replace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m   8108\u001b[0m         is_re_compilable(regex)\n\u001b[1;32m   8109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_list_like(regex)\n\u001b[1;32m   8110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_dict_like(regex)\n\u001b[1;32m   8111\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/base.py:278\u001b[0m, in \u001b[0;36mDataManager.replace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_with_block(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace_list\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    280\u001b[0m     src_list\u001b[38;5;241m=\u001b[39msrc_list,\n\u001b[1;32m    281\u001b[0m     dest_list\u001b[38;5;241m=\u001b[39mdest_list,\n\u001b[1;32m    282\u001b[0m     inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m    283\u001b[0m     regex\u001b[38;5;241m=\u001b[39mregex,\n\u001b[1;32m    284\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    285\u001b[0m     already_warned\u001b[38;5;241m=\u001b[39m_AlreadyWarned(),\n\u001b[1;32m    286\u001b[0m )\n\u001b[1;32m    287\u001b[0m bm\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1101\u001b[0m, in \u001b[0;36mBlock.replace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex, using_cow, already_warned)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         already_warned\u001b[38;5;241m.\u001b[39mwarned_already \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m opt \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture.no_silent_downcasting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ((src, dest), mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(pairs, masks)):\n\u001b[1;32m   1102\u001b[0m     convert \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m==\u001b[39m src_len  \u001b[38;5;66;03m# only convert once at the end\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m     new_rb: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1064\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_string_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# Calculate the mask once, prior to the call of comp\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;66;03m# in order to avoid repeating the same computations\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m     na_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39misna(values)\n\u001b[1;32m   1060\u001b[0m     masks: Iterable[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_]] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m         extract_bool_array(\n\u001b[1;32m   1062\u001b[0m             cast(\n\u001b[1;32m   1063\u001b[0m                 ArrayLike,\n\u001b[0;32m-> 1064\u001b[0m                 compare_or_regex_search(\n\u001b[1;32m   1065\u001b[0m                     values, s[\u001b[38;5;241m0\u001b[39m], regex\u001b[38;5;241m=\u001b[39mregex, mask\u001b[38;5;241m=\u001b[39mna_mask\n\u001b[1;32m   1066\u001b[0m                 ),\n\u001b[1;32m   1067\u001b[0m             )\n\u001b[1;32m   1068\u001b[0m         )\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m pairs\n\u001b[1;32m   1070\u001b[0m     )\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;66;03m# GH#38086 faster if we know we dont need to check for regex\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m     masks \u001b[38;5;241m=\u001b[39m (missing\u001b[38;5;241m.\u001b[39mmask_missing(values, s[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m pairs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/array_algos/replace.py:98\u001b[0m, in \u001b[0;36mcompare_or_regex_search\u001b[0;34m(a, b, regex, mask)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     96\u001b[0m     a \u001b[38;5;241m=\u001b[39m a[mask]\n\u001b[0;32m---> 98\u001b[0m result \u001b[38;5;241m=\u001b[39m op(a)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# The shape of the mask can differ to that of the result\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# since we may compare only a subset of a's or b's elements\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(mask\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_as_normal(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[1;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39mvargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/function_base.py:2455\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;66;03m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m   2453\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [asanyarray(a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m-> 2455\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ufunc(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mnout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2458\u001b[0m     res \u001b[38;5;241m=\u001b[39m asanyarray(outputs, dtype\u001b[38;5;241m=\u001b[39motypes[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/array_algos/replace.py:89\u001b[0m, in \u001b[0;36mcompare_or_regex_search.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     86\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: operator\u001b[38;5;241m.\u001b[39meq(x, b)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     op \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvectorize(\n\u001b[0;32m---> 89\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mbool\u001b[39m(re\u001b[38;5;241m.\u001b[39msearch(b, x))\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mstr\u001b[39m, Pattern))\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# GH#32621 use mask to avoid comparing to NAs\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/re/__init__.py:177\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply data processing script\n",
    "df = process_data()\n",
    "\n",
    "# Check DataFrame head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, test and validation sets\n",
    "x = df.drop(columns=['PotentialFraud'])\n",
    "y = df['PotentialFraud']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to train baseline models\n",
    "def train_optimized_classification_models(X_train, X_test, y_train, y_test, n_iter=10):\n",
    "    param_distributions = {\n",
    "        \"Logistic Regression\": {\n",
    "            \"model\": LogisticRegression(),\n",
    "            \"params\": {\"C\": np.logspace(-3, 3, 10), \"penalty\": [\"l1\", \"l2\"], \"solver\": [\"liblinear\"]}\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestClassifier(random_state=42),\n",
    "            \"params\": {\"n_estimators\": np.arange(50, 300, 50), \"max_depth\": [5, 10, None], \"min_samples_split\": [2, 5, 10]}\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            \"params\": {\"n_estimators\": np.arange(50, 300, 50), \"learning_rate\": np.linspace(0.01, 0.2, 5), \"max_depth\": [3, 5, 10]}\n",
    "        },\n",
    "        \"Gaussian Naïve Bayes\": {\n",
    "            \"model\": GaussianNB(),\n",
    "            \"params\": {\"var_smoothing\": np.logspace(-9, -6, 10)}\n",
    "        },\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "    for name, config in param_distributions.items():\n",
    "        print(f\"\\nTraining and tuning {name}...\")\n",
    "\n",
    "        if name == \"Gaussian Naïve Bayes\":\n",
    "            model = config[\"model\"]\n",
    "            model.fit(x_train, y_train)\n",
    "            best_model = model\n",
    "            best_params = None  \n",
    "        else:\n",
    "            random_search = RandomizedSearchCV(\n",
    "                config[\"model\"], config[\"params\"], n_iter=n_iter, cv=5, scoring=\"f1\", n_jobs=-1, random_state=42\n",
    "            )\n",
    "            random_search.fit(x_train, y_train)\n",
    "            best_model = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "\n",
    "        cv_scores = cross_val_score(best_model, x_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "        y_pred = best_model.predict(x_val)\n",
    "        y_prob = best_model.predict_proba(x_val)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "        metrics = {\n",
    "            \"Best Params\": best_params,\n",
    "            \"Cross-Validation F1 (Mean)\": np.mean(cv_scores),\n",
    "            \"Accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"Precision\": precision_score(y_val, y_pred),\n",
    "            \"Recall\": recall_score(y_val, y_pred),\n",
    "            \"F1 Score\": f1_score(y_val, y_pred),\n",
    "            \"ROC AUC\": roc_auc_score(y_val, y_prob) if y_prob is not None else None\n",
    "        }\n",
    "\n",
    "        best_models[name] = {\"model\": best_model, \"metrics\": metrics}\n",
    "\n",
    "        print(f\"\\n{name} Best Parameters: {best_params}\")\n",
    "        for metric, value in metrics.items():\n",
    "            if metric != \"Best Params\":\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the optimized classification models\n",
    "results = train_optimized_classification_models(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to train and predict ensemble model metrics\n",
    "def train_voting_ensemble(models, X_train, X_test, y_train, y_test):\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"Random Forest\", models[\"Random Forest\"][\"model\"]),\n",
    "            (\"Logistic Regression\", models[\"Logistic Regression\"][\"model\"]),\n",
    "            (\"XGBoost\", models[\"XGBoost\"][\"model\"])\n",
    "        ],\n",
    "        voting=\"soft\"  # Soft voting considers probability predictions\n",
    "    )\n",
    "\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate the ensemble model\n",
    "def evaluate_final_model(model, X_train, y_train, X_test, y_test, cv=5):\n",
    "    # Predict the values for each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Calculate cross-validation scores    \n",
    "    cv_f1_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "    cross_val_f1_mean = np.mean(cv_f1_scores)\n",
    "\n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        \"Cross-Validation F1 (Mean)\": cross_val_f1_mean,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"Cohen's Kappa\": cohen_kappa_score(y_test, y_pred),\n",
    "        \"Matthews Corr Coeff (MCC)\": matthews_corrcoef(y_test, y_pred),\n",
    "        \"Log Loss\": log_loss(y_test, y_prob) if y_prob is not None else None,\n",
    "        \"ROC AUC Score\": roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "    }\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nFinal Model Performance on Test Set:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Print metrics\n",
    "    for metric, value in metrics.items():\n",
    "        if value is not None:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:08:08] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Estimate the voting model classifier\n",
    "voting_model = train_voting_ensemble(results, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:11:46] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:14:09] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:33] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:18:51] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:21:11] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     69241\n",
      "           1       1.00      0.87      0.93     42735\n",
      "\n",
      "    accuracy                           0.95    111976\n",
      "   macro avg       0.96      0.93      0.94    111976\n",
      "weighted avg       0.95      0.95      0.95    111976\n",
      "\n",
      "Cross-Validation F1 (Mean): 0.9195\n",
      "Accuracy: 0.9476\n",
      "Precision: 0.9973\n",
      "Recall: 0.8651\n",
      "F1 Score: 0.9265\n",
      "Balanced Accuracy: 0.9318\n",
      "Cohen's Kappa: 0.8862\n",
      "Matthews Corr Coeff (MCC): 0.8916\n",
      "Log Loss: 0.2067\n",
      "ROC AUC Score: 0.9882\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the voting model classifier\n",
    "final_metrics = evaluate_final_model(voting_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to create a stacking classifier\n",
    "def stacking_classifier(x_val, y_val, x_test, y_test, base:list, meta_model, gs_grid=None, **gs_args):\n",
    "    # Create DataFrame of predicted values for validation and test sets\n",
    "    meta_features = np.column_stack([model.predict(x_val) for model in base])\n",
    "    test_meta_features = np.column_stack([model.predict(x_test) for model in base])\n",
    "\n",
    "    # Fit model\n",
    "    if gs_grid==None:\n",
    "        best_model = meta_model.fit(meta_features, y_val)\n",
    "    else:\n",
    "        meta_gs = GridSearchCV(meta_model, gs_grid, gs_args)\n",
    "        meta_gs.fit(meta_features, y_val)\n",
    "        best_model = meta_gs.best_estimator_\n",
    "\n",
    "    # Predict classes and probability        \n",
    "    final_pred = best_model.predict(test_meta_features)\n",
    "    final_prob = best_model.predict_proba(test_meta_features)[:, 1] if hasattr(meta_model, \"predict_proba\") else None\n",
    "\n",
    "    # Calculate classification metrics\n",
    "    metrics = {\n",
    "            \"Accuracy\": accuracy_score(y_test, final_pred),\n",
    "            \"Precision\": precision_score(y_test, final_pred),\n",
    "            \"Recall\": recall_score(y_test, final_pred),\n",
    "            \"F1 Score\": f1_score(y_test, final_pred),\n",
    "            \"ROC AUC\": roc_auc_score(y_test, final_prob) if final_prob is not None else None\n",
    "        }\n",
    "\n",
    "    # Combine model and metrics\n",
    "    final_model = {'model': best_model, 'metrics': metrics, 'pred': final_pred, 'pred_prob': final_prob}\n",
    "\n",
    "    # Output the final results\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "lr = results['Logistic Regression']['model']\n",
    "rf = results['Random Forest']['model']\n",
    "xgb = results['XGBoost']['model']\n",
    "gnb = results['Gaussian Naïve Bayes']['model']\n",
    "\n",
    "# Create base models list\n",
    "base_models = [\n",
    "    lr,\n",
    "    rf,\n",
    "    xgb,\n",
    "    gnb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "meta_lr = LogisticRegression()\n",
    "\n",
    "# Get results\n",
    "logit_results = stacking_classifier(x_val, y_val, x_test, y_test, base_models, meta_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "meta_svm = SVC()\n",
    "\n",
    "# Define the grid for the SVM\n",
    "svc_params = {'kernel':['rbf', 'poly'],\n",
    "              'degree':[2, 3, 4,],\n",
    "              'C':[.01, .1, 1], \n",
    "              'gamma':['scale', 'auto']}\n",
    "\n",
    "# SVM meta-model\n",
    "svm_results = stacking_classifier(x_val, y_val, x_test, y_test, base_models, meta_svm, meta_gs=svc_params, cv=5, scoring='f1', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(),\n",
       " 'metrics': {'Accuracy': 0.9763699364149461,\n",
       "  'Precision': 0.9981608966871287,\n",
       "  'Recall': 0.9398151398151399,\n",
       "  'F1 Score': 0.968109723762233,\n",
       "  'ROC AUC': 0.9730974921483434}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get logit meta model results\n",
    "logit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': SVC(),\n",
       " 'metrics': {'Accuracy': 0.9764592412659856,\n",
       "  'Precision': 0.9978891951625319,\n",
       "  'Recall': 0.9403065403065403,\n",
       "  'F1 Score': 0.9682424943376223,\n",
       "  'ROC AUC': None}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get SVM meta-model results\n",
    "svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict contender models on test set\n",
    "xgb_pred = xgb.predict(x_test)\n",
    "stack_log_pred = logit_results['pred']\n",
    "stack_svm_pred = svm_results['pred']\n",
    "\n",
    "# Add labels and predictions to x_test\n",
    "test_full = x_test.copy()\n",
    "test_full['label'] = y_test\n",
    "test_full['xgb_pred'] = xgb_pred\n",
    "test_full['stack_log_pred'] = stack_log_pred\n",
    "test_full['stack_svm_pred'] = stack_svm_pred\n",
    "test_full['tot_reimburse'] = test_full['IPAnnualReimbursementAmt'] + test_full['OPAnnualReimbursementAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total amount of fraudulent reimbursements on the test data\n",
    "tot_fraud = test_full[test_full['label'] == 1]['tot_reimburse'].sum()\n",
    "\n",
    "# Create a list to store results\n",
    "monetary = []\n",
    "\n",
    "# Calculate monetary value of each model\n",
    "for col in ['xgb_pred', 'stack_log_pred', 'stack_svm_pred']:\n",
    "    # Amount of fraud predicted as fraud\n",
    "    pred_fraud = test_full[(test_full['label'] == 1) & (test_full[col] == 1)]['tot_reimburse'].sum()\n",
    "\n",
    "    # Amount of fraud predicted as not-fraud\n",
    "    miss_fraud = test_full[(test_full['label'] == 1) & (test_full[col] == 0)]['tot_reimburse'].sum()\n",
    "\n",
    "    # Percentage of fraud predicted as fraud\n",
    "    pct_pred_fraud = pred_fraud/tot_fraud\n",
    "\n",
    "    # Percentage of fraud predicted as not-fraud\n",
    "    pct_miss_fraud = miss_fraud/tot_fraud\n",
    "\n",
    "    # Add the results to the list\n",
    "    monetary.append({'model':col, 'tot_fraud':tot_fraud, 'pred_fraud':pred_fraud, 'miss_fraud':miss_fraud, 'pct_pred_fraud':pct_pred_fraud, 'pct_miss_fraud':pct_miss_fraud})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tot_fraud</th>\n",
       "      <th>pred_fraud</th>\n",
       "      <th>miss_fraud</th>\n",
       "      <th>pct_pred_fraud</th>\n",
       "      <th>pct_miss_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb_pred</td>\n",
       "      <td>347745110</td>\n",
       "      <td>326034460</td>\n",
       "      <td>21710650</td>\n",
       "      <td>0.937567</td>\n",
       "      <td>0.062433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stack_log_pred</td>\n",
       "      <td>347745110</td>\n",
       "      <td>326034460</td>\n",
       "      <td>21710650</td>\n",
       "      <td>0.937567</td>\n",
       "      <td>0.062433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stack_svm_pred</td>\n",
       "      <td>347745110</td>\n",
       "      <td>326185120</td>\n",
       "      <td>21559990</td>\n",
       "      <td>0.938001</td>\n",
       "      <td>0.061999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  tot_fraud  pred_fraud  miss_fraud  pct_pred_fraud  \\\n",
       "0        xgb_pred  347745110   326034460    21710650        0.937567   \n",
       "1  stack_log_pred  347745110   326034460    21710650        0.937567   \n",
       "2  stack_svm_pred  347745110   326185120    21559990        0.938001   \n",
       "\n",
       "   pct_miss_fraud  \n",
       "0        0.062433  \n",
       "1        0.062433  \n",
       "2        0.061999  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check monetary values\n",
    "df_monetary = pd.DataFrame(monetary)\n",
    "df_monetary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
