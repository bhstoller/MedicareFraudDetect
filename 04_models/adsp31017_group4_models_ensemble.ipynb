{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicare Fraud - Stacking Models\n",
    "\n",
    "Mustapha Mbengue, Peyton Nash, Bradley Stoller, Kyler Rosen\n",
    "\n",
    "3/9/25\n",
    "\n",
    "Purpose: Specifies, trains and evaluates stacking models to classify cases of medicare fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change path to read in the data processing\n",
    "sys.path.append(os.path.abspath(\"../03_data-preprocessing\"))\n",
    "\n",
    "# Function to pre-process this data\n",
    "from adsp31017_group4_data_preprocessing import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "Merging raw data...\n",
      "Merged raw data. Time elapsed: 10.65s\n",
      "Correcting codes...\n",
      "Corrected codes. Time elapsed: 51.55s\n",
      "Loading the dataframe...\n",
      "Loaded the dataframe. Time elapsed: 57.04s\n",
      "Starting feature engineering...\n",
      "Adding datetime features...\n",
      "Added datetime features. Time elapsed: 14.22s\n",
      "Discretizing age...\n",
      "Discretized age. Time elapsed: 14.23s\n",
      "Filling in missing values...\n",
      "Filled in missing values. Time elapsed: 15.81s\n",
      "Transforming skewed distributions...\n",
      "Transformed skewed distributions. Time elapsed: 15.82s\n",
      "Encoding categorical columns...\n",
      "Encoded categorical columns. Time elapsed: 18.81s\n",
      "Dropping unnecessary columns...\n",
      "Dropped unnecessary columns. Time elapsed: 18.89s\n",
      "Feature engineering complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>AttendingPhysician</th>\n",
       "      <th>OperatingPhysician</th>\n",
       "      <th>OtherPhysician</th>\n",
       "      <th>ClmAdmitDiagnosisCode</th>\n",
       "      <th>TotalClaims</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>RenalDiseaseIndicator</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>NumProcedures</th>\n",
       "      <th>HospitalStayDays</th>\n",
       "      <th>ClaimDuration</th>\n",
       "      <th>DaysBeforeAdmission</th>\n",
       "      <th>ClaimStartMonth</th>\n",
       "      <th>ClaimStartWeekday</th>\n",
       "      <th>ClaimStartYear</th>\n",
       "      <th>DaysSinceLastClaim</th>\n",
       "      <th>AgeAtClaim</th>\n",
       "      <th>AgeGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3928</td>\n",
       "      <td>53275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3022</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3923</td>\n",
       "      <td>4951</td>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>2298</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>141.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4034</td>\n",
       "      <td>40843</td>\n",
       "      <td>0</td>\n",
       "      <td>5202</td>\n",
       "      <td>851</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1125</td>\n",
       "      <td>39020</td>\n",
       "      <td>23576</td>\n",
       "      <td>14718</td>\n",
       "      <td>1602</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1125</td>\n",
       "      <td>39020</td>\n",
       "      <td>23576</td>\n",
       "      <td>14718</td>\n",
       "      <td>1602</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  AttendingPhysician  OperatingPhysician  OtherPhysician  \\\n",
       "0      3928               53275                   0               0   \n",
       "1      3923                4951                2133               0   \n",
       "2      4034               40843                   0            5202   \n",
       "3      1125               39020               23576           14718   \n",
       "4      1125               39020               23576           14718   \n",
       "\n",
       "   ClmAdmitDiagnosisCode  TotalClaims  Gender  Race  RenalDiseaseIndicator  \\\n",
       "0                   3022           60       1     1                      0   \n",
       "1                   2298           60       1     1                      0   \n",
       "2                    851           14       1     1                      0   \n",
       "3                   1602           22       2     2                      0   \n",
       "4                   1602           22       2     2                      0   \n",
       "\n",
       "   State  ...  NumProcedures  HospitalStayDays  ClaimDuration  \\\n",
       "0     39  ...              6               6.0              6   \n",
       "1     39  ...              6               2.0              2   \n",
       "2     39  ...              6               3.0              3   \n",
       "3      1  ...              6               8.0              8   \n",
       "4      1  ...              6               8.0              8   \n",
       "\n",
       "   DaysBeforeAdmission  ClaimStartMonth  ClaimStartWeekday  ClaimStartYear  \\\n",
       "0                  0.0                4                  6            2009   \n",
       "1                  0.0                8                  0            2009   \n",
       "2                  0.0                9                  3            2009   \n",
       "3                  0.0                2                  5            2009   \n",
       "4                  0.0                2                  5            2009   \n",
       "\n",
       "   DaysSinceLastClaim  AgeAtClaim  AgeGroup  \n",
       "0                 0.0          66         2  \n",
       "1               141.0          66         2  \n",
       "2                17.0          66         2  \n",
       "3                 0.0          95         3  \n",
       "4                 0.0          95         3  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply data processing script\n",
    "df = process_data()\n",
    "\n",
    "# Check DataFrame head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, test and validation sets\n",
    "x = df.drop(columns=['PotentialFraud'])\n",
    "y = df['PotentialFraud']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to train baseline models\n",
    "def train_optimized_classification_models(X_train, X_test, y_train, y_test, n_iter=10):\n",
    "    param_distributions = {\n",
    "        \"Logistic Regression\": {\n",
    "            \"model\": LogisticRegression(),\n",
    "            \"params\": {\"C\": np.logspace(-3, 3, 10), \"penalty\": [\"l1\", \"l2\"], \"solver\": [\"liblinear\"]}\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestClassifier(random_state=42),\n",
    "            \"params\": {\"n_estimators\": np.arange(50, 300, 50), \"max_depth\": [5, 10, None], \"min_samples_split\": [2, 5, 10]}\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            \"params\": {\"n_estimators\": np.arange(50, 300, 50), \"learning_rate\": np.linspace(0.01, 0.2, 5), \"max_depth\": [3, 5, 10]}\n",
    "        },\n",
    "        \"Gaussian Naïve Bayes\": {\n",
    "            \"model\": GaussianNB(),\n",
    "            \"params\": {\"var_smoothing\": np.logspace(-9, -6, 10)}\n",
    "        },\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "    for name, config in param_distributions.items():\n",
    "        print(f\"\\nTraining and tuning {name}...\")\n",
    "\n",
    "        if name == \"Gaussian Naïve Bayes\":\n",
    "            model = config[\"model\"]\n",
    "            model.fit(x_train, y_train)\n",
    "            best_model = model\n",
    "            best_params = None  \n",
    "        else:\n",
    "            random_search = RandomizedSearchCV(\n",
    "                config[\"model\"], config[\"params\"], n_iter=n_iter, cv=5, scoring=\"f1\", n_jobs=-1, random_state=42\n",
    "            )\n",
    "            random_search.fit(x_train, y_train)\n",
    "            best_model = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "\n",
    "        cv_scores = cross_val_score(best_model, x_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "        y_pred = best_model.predict(x_val)\n",
    "        y_prob = best_model.predict_proba(x_val)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "        metrics = {\n",
    "            \"Best Params\": best_params,\n",
    "            \"Cross-Validation F1 (Mean)\": np.mean(cv_scores),\n",
    "            \"Accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"Precision\": precision_score(y_val, y_pred),\n",
    "            \"Recall\": recall_score(y_val, y_pred),\n",
    "            \"F1 Score\": f1_score(y_val, y_pred),\n",
    "            \"ROC AUC\": roc_auc_score(y_val, y_prob) if y_prob is not None else None\n",
    "        }\n",
    "\n",
    "        best_models[name] = {\"model\": best_model, \"metrics\": metrics}\n",
    "\n",
    "        print(f\"\\n{name} Best Parameters: {best_params}\")\n",
    "        for metric, value in metrics.items():\n",
    "            if metric != \"Best Params\":\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the optimized classification models\n",
    "results = train_optimized_classification_models(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to train and predict ensemble model metrics\n",
    "def train_voting_ensemble(models, X_train, X_test, y_train, y_test):\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"Random Forest\", models[\"Random Forest\"][\"model\"]),\n",
    "            (\"Logistic Regression\", models[\"Logistic Regression\"][\"model\"]),\n",
    "            (\"XGBoost\", models[\"XGBoost\"][\"model\"])\n",
    "        ],\n",
    "        voting=\"soft\"  # Soft voting considers probability predictions\n",
    "    )\n",
    "\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate the ensemble model\n",
    "def evaluate_final_model(model, X_train, y_train, X_test, y_test, cv=5):\n",
    "    # Predict the values for each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Calculate cross-validation scores    \n",
    "    cv_f1_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "    cross_val_f1_mean = np.mean(cv_f1_scores)\n",
    "\n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        \"Cross-Validation F1 (Mean)\": cross_val_f1_mean,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"Cohen's Kappa\": cohen_kappa_score(y_test, y_pred),\n",
    "        \"Matthews Corr Coeff (MCC)\": matthews_corrcoef(y_test, y_pred),\n",
    "        \"Log Loss\": log_loss(y_test, y_prob) if y_prob is not None else None,\n",
    "        \"ROC AUC Score\": roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "    }\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nFinal Model Performance on Test Set:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Print metrics\n",
    "    for metric, value in metrics.items():\n",
    "        if value is not None:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:08:08] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Estimate the voting model classifier\n",
    "voting_model = train_voting_ensemble(results, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:11:46] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:14:09] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:16:33] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:18:51] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:21:11] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Performance on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     69241\n",
      "           1       1.00      0.87      0.93     42735\n",
      "\n",
      "    accuracy                           0.95    111976\n",
      "   macro avg       0.96      0.93      0.94    111976\n",
      "weighted avg       0.95      0.95      0.95    111976\n",
      "\n",
      "Cross-Validation F1 (Mean): 0.9195\n",
      "Accuracy: 0.9476\n",
      "Precision: 0.9973\n",
      "Recall: 0.8651\n",
      "F1 Score: 0.9265\n",
      "Balanced Accuracy: 0.9318\n",
      "Cohen's Kappa: 0.8862\n",
      "Matthews Corr Coeff (MCC): 0.8916\n",
      "Log Loss: 0.2067\n",
      "ROC AUC Score: 0.9882\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the voting model classifier\n",
    "final_metrics = evaluate_final_model(voting_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to create a stacking classifier\n",
    "def stacking_classifier(x_val, y_val, x_test, y_test, base:list, meta_model, gs_grid=None, **gs_args):\n",
    "    # Create DataFrame of predicted values for validation and test sets\n",
    "    meta_features = np.column_stack([model.predict(x_val) for model in base])\n",
    "    test_meta_features = np.column_stack([model.predict(x_test) for model in base])\n",
    "\n",
    "    # Fit model\n",
    "    if gs_grid==None:\n",
    "        best_model = meta_model.fit(meta_features, y_val)\n",
    "    else:\n",
    "        meta_gs = GridSearchCV(meta_model, gs_grid, gs_args)\n",
    "        meta_gs.fit(meta_features, y_val)\n",
    "        best_model = meta_gs.best_estimator_\n",
    "\n",
    "    # Predict classes and probability        \n",
    "    final_pred = best_model.predict(test_meta_features)\n",
    "    final_prob = best_model.predict_proba(test_meta_features)[:, 1] if hasattr(meta_model, \"predict_proba\") else None\n",
    "\n",
    "    # Calculate classification metrics\n",
    "    metrics = {\n",
    "            \"Accuracy\": accuracy_score(y_test, final_pred),\n",
    "            \"Precision\": precision_score(y_test, final_pred),\n",
    "            \"Recall\": recall_score(y_test, final_pred),\n",
    "            \"F1 Score\": f1_score(y_test, final_pred),\n",
    "            \"ROC AUC\": roc_auc_score(y_test, final_prob) if final_prob is not None else None\n",
    "        }\n",
    "\n",
    "    # Combine model and metrics\n",
    "    final_model = {'model': best_model, 'metrics': metrics, 'pred': final_pred, 'pred_prob': final_prob}\n",
    "\n",
    "    # Output the final results\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "lr = results['Logistic Regression']['model']\n",
    "rf = results['Random Forest']['model']\n",
    "xgb = results['XGBoost']['model']\n",
    "gnb = results['Gaussian Naïve Bayes']['model']\n",
    "\n",
    "# Create base models list\n",
    "base_models = [\n",
    "    lr,\n",
    "    rf,\n",
    "    xgb,\n",
    "    gnb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "meta_lr = LogisticRegression()\n",
    "\n",
    "# Get results\n",
    "logit_results = stacking_classifier(x_val, y_val, x_test, y_test, base_models, meta_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "meta_svm = SVC()\n",
    "\n",
    "# Define the grid for the SVM\n",
    "svc_params = {'kernel':['rbf', 'poly'],\n",
    "              'degree':[2, 3, 4,],\n",
    "              'C':[.01, .1, 1], \n",
    "              'gamma':['scale', 'auto']}\n",
    "\n",
    "# SVM meta-model\n",
    "svm_results = stacking_classifier(x_val, y_val, x_test, y_test, base_models, meta_svm, meta_gs=svc_params, cv=5, scoring='f1', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(),\n",
       " 'metrics': {'Accuracy': 0.9763699364149461,\n",
       "  'Precision': 0.9981608966871287,\n",
       "  'Recall': 0.9398151398151399,\n",
       "  'F1 Score': 0.968109723762233,\n",
       "  'ROC AUC': 0.9730974921483434}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get logit meta model results\n",
    "logit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': SVC(),\n",
       " 'metrics': {'Accuracy': 0.9764592412659856,\n",
       "  'Precision': 0.9978891951625319,\n",
       "  'Recall': 0.9403065403065403,\n",
       "  'F1 Score': 0.9682424943376223,\n",
       "  'ROC AUC': None}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get SVM meta-model results\n",
    "svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict contender models on test set\n",
    "xgb_pred = xgb.predict(x_test)\n",
    "stack_log_pred = logit_results['pred']\n",
    "stack_svm_pred = svm_results['pred']\n",
    "\n",
    "# Add labels and predictions to x_test\n",
    "test_full = x_test.copy()\n",
    "test_full['label'] = y_test\n",
    "test_full['xgb_pred'] = xgb_pred\n",
    "test_full['stack_log_pred'] = stack_log_pred\n",
    "test_full['stack_svm_pred'] = stack_svm_pred\n",
    "test_full['tot_reimburse'] = test_full['IPAnnualReimbursementAmt'] + test_full['OPAnnualReimbursementAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total amount of fraudulent reimbursements on the test data\n",
    "tot_fraud = test_full[test_full['label'] == 1]['tot_reimburse'].sum()\n",
    "\n",
    "# Create a list to store results\n",
    "monetary = []\n",
    "\n",
    "# Calculate monetary value of each model\n",
    "for col in ['xgb_pred', 'stack_log_pred', 'stack_svm_pred']:\n",
    "    # Amount of fraud predicted as fraud\n",
    "    pred_fraud = test_full[(test_full['label'] == 1) & (test_full[col] == 1)]['tot_reimburse'].sum()\n",
    "\n",
    "    # Amount of fraud predicted as not-fraud\n",
    "    miss_fraud = test_full[(test_full['label'] == 1) & (test_full[col] == 0)]['tot_reimburse'].sum()\n",
    "\n",
    "    # Percentage of fraud predicted as fraud\n",
    "    pct_pred_fraud = pred_fraud/tot_fraud\n",
    "\n",
    "    # Percentage of fraud predicted as not-fraud\n",
    "    pct_miss_fraud = miss_fraud/tot_fraud\n",
    "\n",
    "    # Add the results to the list\n",
    "    monetary.append({'model':col, 'tot_fraud':tot_fraud, 'pred_fraud':pred_fraud, 'miss_fraud':miss_fraud, 'pct_pred_fraud':pct_pred_fraud, 'pct_miss_fraud':pct_miss_fraud})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tot_fraud</th>\n",
       "      <th>pred_fraud</th>\n",
       "      <th>miss_fraud</th>\n",
       "      <th>pct_pred_fraud</th>\n",
       "      <th>pct_miss_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb_pred</td>\n",
       "      <td>347745110</td>\n",
       "      <td>326034460</td>\n",
       "      <td>21710650</td>\n",
       "      <td>0.937567</td>\n",
       "      <td>0.062433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stack_log_pred</td>\n",
       "      <td>347745110</td>\n",
       "      <td>326034460</td>\n",
       "      <td>21710650</td>\n",
       "      <td>0.937567</td>\n",
       "      <td>0.062433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stack_svm_pred</td>\n",
       "      <td>347745110</td>\n",
       "      <td>326185120</td>\n",
       "      <td>21559990</td>\n",
       "      <td>0.938001</td>\n",
       "      <td>0.061999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  tot_fraud  pred_fraud  miss_fraud  pct_pred_fraud  \\\n",
       "0        xgb_pred  347745110   326034460    21710650        0.937567   \n",
       "1  stack_log_pred  347745110   326034460    21710650        0.937567   \n",
       "2  stack_svm_pred  347745110   326185120    21559990        0.938001   \n",
       "\n",
       "   pct_miss_fraud  \n",
       "0        0.062433  \n",
       "1        0.062433  \n",
       "2        0.061999  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check monetary values\n",
    "df_monetary = pd.DataFrame(monetary)\n",
    "df_monetary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
