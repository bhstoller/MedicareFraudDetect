{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicare Fraud - Stacking Models\n",
    "\n",
    "Mustapha Mbengue, Peyton Nash, Bradley Stoller, Kyler Rosen\n",
    "\n",
    "3/9/25\n",
    "\n",
    "Purpose: Specifies, trains and evaluates stacking models to classify cases of medicare fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from data_loading import load_data\n",
    "from feature_engineering import apply_feature_engineering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering...\n",
      "Adding datetime features...\n",
      "Added datetime features. Time elapsed: 14.90s\n",
      "Discretizing age...\n",
      "Discretized age. Time elapsed: 14.91s\n",
      "Filling in missing values...\n",
      "Filled in missing values. Time elapsed: 16.54s\n",
      "Transforming skewed distributions...\n",
      "Transformed skewed distributions. Time elapsed: 16.55s\n",
      "Encoding categorical columns...\n",
      "Encoded categorical columns. Time elapsed: 19.53s\n",
      "Dropping unnecessary columns...\n",
      "Dropped unnecessary columns. Time elapsed: 19.65s\n",
      "Feature engineering complete!\n"
     ]
    }
   ],
   "source": [
    "# Apply data engineering\n",
    "df = apply_feature_engineering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to train baseline models\n",
    "def train_optimized_classification_models(data, target_column, n_iter=10):\n",
    "    x = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "    param_distributions = {\n",
    "        \"Logistic Regression\": {\n",
    "            \"model\": LogisticRegression(),\n",
    "            \"params\": {\"C\": np.logspace(-3, 3, 10), \"penalty\": [\"l1\", \"l2\"], \"solver\": [\"liblinear\"]}\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestClassifier(random_state=42),\n",
    "            \"params\": {\"n_estimators\": np.arange(50, 300, 50), \"max_depth\": [5, 10, None], \"min_samples_split\": [2, 5, 10]}\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            \"params\": {\"n_estimators\": np.arange(50, 300, 50), \"learning_rate\": np.linspace(0.01, 0.2, 5), \"max_depth\": [3, 5, 10]}\n",
    "        },\n",
    "        \"Gaussian Naïve Bayes\": {\n",
    "            \"model\": GaussianNB(),\n",
    "            \"params\": {\"var_smoothing\": np.logspace(-9, -6, 10)}\n",
    "        },\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "    for name, config in param_distributions.items():\n",
    "        print(f\"\\nTraining and tuning {name}...\")\n",
    "\n",
    "        if name == \"Gaussian Naïve Bayes\":\n",
    "            model = config[\"model\"]\n",
    "            model.fit(x_train, y_train)\n",
    "            best_model = model\n",
    "            best_params = None  \n",
    "        else:\n",
    "            random_search = RandomizedSearchCV(\n",
    "                config[\"model\"], config[\"params\"], n_iter=n_iter, cv=5, scoring=\"f1\", n_jobs=-1, random_state=42\n",
    "            )\n",
    "            random_search.fit(x_train, y_train)\n",
    "            best_model = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "\n",
    "        cv_scores = cross_val_score(best_model, x_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "        y_pred = best_model.predict(x_val)\n",
    "        y_prob = best_model.predict_proba(x_val)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "        metrics = {\n",
    "            \"Best Params\": best_params,\n",
    "            \"Cross-Validation F1 (Mean)\": np.mean(cv_scores),\n",
    "            \"Accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"Precision\": precision_score(y_val, y_pred),\n",
    "            \"Recall\": recall_score(y_val, y_pred),\n",
    "            \"F1 Score\": f1_score(y_val, y_pred),\n",
    "            \"ROC AUC\": roc_auc_score(y_val, y_prob) if y_prob is not None else None\n",
    "        }\n",
    "\n",
    "        best_models[name] = {\"model\": best_model, \"metrics\": metrics}\n",
    "\n",
    "        print(f\"\\n{name} Best Parameters: {best_params}\")\n",
    "        for metric, value in metrics.items():\n",
    "            if metric != \"Best Params\":\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of the optimized classification models\n",
    "results = train_optimized_classification_models(df, 'PotentialFraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, test and validation sets\n",
    "x = df.drop(columns=['PotentialFraud'])\n",
    "y = df['PotentialFraud']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to create a stacking classifier\n",
    "def stacking_classifier(x_val, y_val, x_test, y_test, base:list, meta_model, gs_grid=None, **gs_args):\n",
    "    # Create DataFrame of predicted values for validation and test sets\n",
    "    meta_features = np.column_stack([model.predict(x_val) for model in base])\n",
    "    test_meta_features = np.column_stack([model.predict(x_test) for model in base])\n",
    "\n",
    "    # Fit model\n",
    "    if gs_grid==None:\n",
    "        best_model = meta_model.fit(meta_features, y_val)\n",
    "    else:\n",
    "        meta_gs = GridSearchCV(meta_model, gs_grid, gs_args)\n",
    "        meta_gs.fit(meta_features, y_val)\n",
    "        best_model = meta_gs.best_estimator_\n",
    "\n",
    "    # Predict classes and probability        \n",
    "    final_pred = best_model.predict(test_meta_features)\n",
    "    final_prob = best_model.predict_proba(test_meta_features)[:, 1] if hasattr(meta_model, \"predict_proba\") else None\n",
    "\n",
    "    # Calculate classification metrics\n",
    "    metrics = {\n",
    "            \"Accuracy\": accuracy_score(y_test, final_pred),\n",
    "            \"Precision\": precision_score(y_test, final_pred),\n",
    "            \"Recall\": recall_score(y_test, final_pred),\n",
    "            \"F1 Score\": f1_score(y_test, final_pred),\n",
    "            \"ROC AUC\": roc_auc_score(y_test, final_prob) if final_prob is not None else None\n",
    "        }\n",
    "\n",
    "    # Combine model and metrics\n",
    "    final_model = {'model': best_model, 'metrics': metrics}\n",
    "\n",
    "    # Output the final results\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "lr = results['Logistic Regression']['model']\n",
    "rf = results['Random Forest']['model']\n",
    "xgb = results['XGBoost']['model']\n",
    "gnb = results['Gaussian Naïve Bayes']['model']\n",
    "\n",
    "# Create base models list\n",
    "base_models = [\n",
    "    lr,\n",
    "    rf,\n",
    "    xgb,\n",
    "    gnb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "meta_lr = LogisticRegression()\n",
    "\n",
    "# Get results\n",
    "logit_results = stacking_classifier(x_val, y_val, x_test, y_test, base_models, meta_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta model\n",
    "meta_svm = SVC()\n",
    "\n",
    "# Define the grid for the SVM\n",
    "svc_params = {'kernel':['rbf', 'poly'],\n",
    "              'degree':[2, 3, 4,],\n",
    "              'C':[.01, .1, 1], \n",
    "              'gamma':['scale', 'auto']}\n",
    "\n",
    "# SVM meta-model\n",
    "svm_results = stacking_classifier(x_val, y_val, x_test, y_test, base_models, meta_svm, meta_gs=svc_params, cv=5, scoring='f1', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(),\n",
       " 'metrics': {'Accuracy': 0.9763699364149461,\n",
       "  'Precision': 0.9981608966871287,\n",
       "  'Recall': 0.9398151398151399,\n",
       "  'F1 Score': 0.968109723762233,\n",
       "  'ROC AUC': 0.9730804793874362}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get logit meta model results\n",
    "logit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get SVM meta-model results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m svm_results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Get SVM meta-model results\n",
    "svm_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
